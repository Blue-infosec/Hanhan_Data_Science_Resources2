{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Data can be down loaded here (need sign in): \n",
    "## https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"Big_Mart_Train.csv\")\n",
    "test_data = pd.read_csv(\"Big_Mart_Test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156.0</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>662.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>10.0</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1297.0</td>\n",
       "      <td>8.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Identifier  Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  \\\n",
       "0            156.0         9.30               1.0         0.016047        4.0   \n",
       "1              8.0         5.92               2.0         0.019278       14.0   \n",
       "2            662.0        17.50               1.0         0.016760       10.0   \n",
       "3           1121.0        19.20               2.0         0.000000        6.0   \n",
       "4           1297.0         8.93               1.0         0.000000        9.0   \n",
       "\n",
       "   Item_MRP  Outlet_Identifier  Outlet_Establishment_Year  Outlet_Size  \\\n",
       "0  249.8092                9.0                         18          1.0   \n",
       "1   48.2692                3.0                          8          1.0   \n",
       "2  141.6180                9.0                         18          1.0   \n",
       "3  182.0950                0.0                         19          1.0   \n",
       "4   53.8614                1.0                         30          0.0   \n",
       "\n",
       "   Outlet_Location_Type  Outlet_Type  Item_Outlet_Sales  \n",
       "0                   0.0          1.0          3735.1380  \n",
       "1                   2.0          2.0           443.4228  \n",
       "2                   0.0          1.0          2097.2700  \n",
       "3                   2.0          0.0           732.3800  \n",
       "4                   2.0          1.0           994.7052  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Item_Weight = train_data.Item_Weight.fillna(np.nanmedian(train_data.Item_Weight))\n",
    "test_data.Item_Weight = test_data.Item_Weight.fillna(np.nanmedian(test_data.Item_Weight))\n",
    "\n",
    "train_data.Outlet_Size = train_data.Outlet_Size.fillna(train_data.Outlet_Size.mode().iloc[0])\n",
    "test_data.Outlet_Size = test_data.Outlet_Size.fillna(test_data.Outlet_Size.mode().iloc[0])\n",
    "\n",
    "train_data.Item_Fat_ContentItem_Fat  = train_data.Item_Fat_Content.replace(['low fat', 'LF'], ['Low Fat', 'Low Fat'])\n",
    "test_data.Item_Fat_Content = test_data.Item_Fat_Content.replace(['low fat', 'LF'], ['Low Fat', 'Low Fat'])\n",
    "train_data.Item_Fat_Content = train_data.Item_Fat_Content.replace(['reg'], ['Regular'])\n",
    "test_data.Item_Fat_Content = test_data.Item_Fat_Content.replace(['reg'], ['Regular'])\n",
    "\n",
    "train_data.Outlet_Establishment_Year = 2017 - train_data.Outlet_Establishment_Year\n",
    "test_data.Outlet_Establishment_Year = 2017 - test_data.Outlet_Establishment_Year\n",
    "\n",
    "test_data['Item_Outlet_Sales'] = 0\n",
    "combi = train_data.append(test_data)\n",
    "number = LabelEncoder()\n",
    "\n",
    "for i in combi.columns:\n",
    "    if (combi[i].dtype == 'object'):\n",
    "        combi[i] = number.fit_transform(combi[i].astype('str'))\n",
    "        combi[i] = combi[i].astype('float')\n",
    "        \n",
    "train_data = combi[:train_data.shape[0]]\n",
    "test_data = combi[train_data.shape[0]:]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train:', array([   1,    2,    3, ..., 8520, 8521, 8522]), 'validation:', array([0]))\n",
      "('train:', array([   0,    2,    3, ..., 8520, 8521, 8522]), 'validation:', array([1]))\n",
      "('train:', array([   0,    1,    3, ..., 8520, 8521, 8522]), 'validation:', array([2]))\n",
      "('train:', array([   0,    1,    2, ..., 8520, 8521, 8522]), 'validation:', array([3]))\n",
      "('train:', array([   0,    1,    2, ..., 8520, 8521, 8522]), 'validation:', array([4]))\n"
     ]
    }
   ],
   "source": [
    "# Leave one out\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(train_data)\n",
    "\n",
    "sample_ct = 0\n",
    "for train_index, validation_index in loo.split(train_data):\n",
    "    print(\"train:\", train_index, \"validation:\", validation_index)\n",
    "    \n",
    "    loo_train = train_data.iloc[train_index]\n",
    "    loo_validation = train_data.iloc[validation_index]\n",
    "    \n",
    "    sample_ct += 1\n",
    "    if sample_ct == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train length:', 6818, 'validation length:', 1705)\n",
      "('train length:', 6818, 'validation length:', 1705)\n",
      "('train length:', 6818, 'validation length:', 1705)\n",
      "('train length:', 6819, 'validation length:', 1704)\n",
      "('train length:', 6819, 'validation length:', 1704)\n"
     ]
    }
   ],
   "source": [
    "# repeated k-fold\n",
    "# # repeat k-fold n times with different randomization in each repetition\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None) \n",
    "\n",
    "sample_ct = 0\n",
    "for train_index, validation_index in kf.split(train_data):\n",
    "    print(\"train length:\", len(train_index), \"validation length:\", len(validation_index))\n",
    "    \n",
    "    kf_train = train_data.iloc[train_index]\n",
    "    kf_validation = train_data.iloc[validation_index]\n",
    "    \n",
    "    sample_ct += 1\n",
    "    if sample_ct == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train length:', 6817, 'validation length:', 1706)\n",
      "('train length:', 6817, 'validation length:', 1706)\n",
      "('train length:', 6818, 'validation length:', 1705)\n",
      "('train length:', 6820, 'validation length:', 1703)\n",
      "('train length:', 6820, 'validation length:', 1703)\n"
     ]
    }
   ],
   "source": [
    "# stratified k-fold, it tries to make sure each fold has similar distribution with other folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=410)\n",
    "# sklearn stratified k-fold only supports binary/multi-class labels, not regression labels, dtype has to be 'category'\n",
    "train_data['Outlet_Type'] = train_data['Outlet_Type'].astype('category')  \n",
    "X = train_data.iloc[:,0:-2]\n",
    "y = train_data.loc[:,'Outlet_Type']\n",
    "\n",
    "sample_ct = 0\n",
    "for train_index, validation_index in skf.split(X, y):\n",
    "    print(\"train length:\", len(train_index), \"validation length:\", len(validation_index))\n",
    "    \n",
    "    skf_train_X = X.iloc[train_index]\n",
    "    skf_validation_X = X.iloc[validation_index]\n",
    "    \n",
    "    skf_train_y = y.iloc[train_index]\n",
    "    skf_validation_y = y.iloc[validation_index]\n",
    "    \n",
    "    sample_ct += 1\n",
    "    if sample_ct == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adversarial Validation\n",
    "# # It checks the degree of similarity between training and tests in terms of feature distribution\n",
    "import xgboost as xgb\n",
    "\n",
    "train_data.drop(['Item_Outlet_Sales'], axis = 1, inplace = True)  # drop label\n",
    "test_data.drop(['Item_Outlet_Sales'], axis = 1, inplace = True)\n",
    "\n",
    "train_data['is_train'] = 1\n",
    "test_data['is_train'] = 0\n",
    "\n",
    "df = pd.concat([train_data, test_data], axis = 0)  # combine training, testing data\n",
    "y = df['is_train']\n",
    "df.drop('is_train', axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.9, gamma=1, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=4, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=410, silent=1,\n",
       "       subsample=0.9)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {'learning_rate': 0.05, \n",
    "              'max_depth': 4,\n",
    "              'subsample': 0.9,        \n",
    "              'colsample_bytree': 0.9,\n",
    "              'objective': 'binary:logistic',\n",
    "              'silent': 1, \n",
    "              'n_estimators':100, \n",
    "              'gamma':1,         \n",
    "              'min_child_weight':4,\n",
    "              'seed': 410}   \n",
    "clf = xgb.XGBClassifier(**xgb_params)  # with \"**\" here, we can resolve the bug in xgboost\n",
    "clf.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56907153,  0.57169026,  0.60950691,  0.96956617,  0.61280704,\n",
       "        0.60482651], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = clf.predict_proba(df)[:,1]\n",
    "probs[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'id':train_data['Item_Identifier'], 'probs':probs[0:len(train_data)]})\n",
    "new_df = new_df.sort_values(by = 'probs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559\n",
      "2555\n"
     ]
    }
   ],
   "source": [
    "val_set_ids = new_df.iloc[1:np.int(new_df.shape[0]*0.3),1]\n",
    "train_set_ids = list(set(train_data['Item_Identifier']) - set(val_set_ids))\n",
    "print len(train_set_ids)\n",
    "print len(val_set_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation for time series\n",
    "# # use all the previous data as training data for the new testing data\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train:', array([0]), 'Validation:', array([1]))\n",
      "[[1 2]] [[3 4]]\n",
      "('Train:', array([0, 1]), 'Validation:', array([2]))\n",
      "[[1 2]\n",
      " [3 4]] [[1 2]]\n",
      "('Train:', array([0, 1, 2]), 'Validation:', array([3]))\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [1 2]] [[3 4]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in tscv.split(X):\n",
    "    print(\"Train:\", train_index, \"Validation:\", val_index)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
